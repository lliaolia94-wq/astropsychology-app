# Система интеллектуального отбора контекста

## Описание

Система интеллектуального отбора контекста для формирования оптимальных промтов LLM, исключая информационную перегрузку.

## Семантический поиск и анализ

### Как работает семантический поиск

Система использует **векторный семантический поиск** для нахождения релевантных исторических событий на основе смыслового сходства с текущим запросом пользователя.

### Технологический стек

1. **Модель эмбеддингов**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
   - Мультиязычная модель (поддерживает русский и английский)
   - Размерность векторов: **384**
   - Библиотека: `sentence-transformers`
   - Настраивается через переменную окружения `EMBEDDING_MODEL`

2. **Векторная база данных**: **Qdrant**
   - Хранение векторных представлений текстов
   - Быстрый поиск по косинусному расстоянию
   - Фильтрация по метаданным (user_id, session_id, tags)

### Процесс семантического поиска

```
1. Текущий запрос пользователя
   ↓
2. Векторизация через SentenceTransformer
   (текст → вектор 384 размерности)
   ↓
3. Поиск в Qdrant по косинусному расстоянию
   (находятся похожие векторы из истории)
   ↓
4. Фильтрация по порогу релевантности
   (score_threshold, по умолчанию 0.6)
   ↓
5. Возврат релевантных событий с оценками
```

### Использование в модулях

#### МОДУЛЬ 1: Приоритет свежести
- Получает семантические оценки релевантности для всех событий
- Использует их как один из факторов при ранжировании
- Комбинирует с временным весом и приоритетом

#### МОДУЛЬ 2: Эмоциональные маркеры
- Создает расширенный запрос: `{текущий_запрос} {ключевые_слова_эмоции}`
- Ищет события с похожей эмоциональной окраской
- Использует порог релевантности: `EMOTIONS_SIMILARITY_THRESHOLD` (0.6)

#### МОДУЛЬ 3: Паттерны повторения
- Использует для улучшения кластеризации событий
- Находит семантически близкие события для текущего запроса
- Порог кластеризации: `PATTERNS_CLUSTERING_THRESHOLD` (0.7)

#### МОДУЛЬ 4: Кармические узлы
- Ищет события, релевантные кармическим темам
- Запрос: `{текущий_запрос} {название_кармической_темы}`
- Порог релевантности: `KARMA_SIMILARITY_THRESHOLD` (0.65)

### Настройка модели

В файле `.env` можно указать другую модель:

```env
# Модель по умолчанию (мультиязычная, 384 размерности)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Альтернативные модели:
# - sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (768 размерности, лучше качество)
# - sentence-transformers/LaBSE (лучше для мультиязычности)
# - intfloat/multilingual-e5-base (современная модель)
```

**Важно**: При смене модели нужно:
1. Изменить `VECTOR_DIMENSION` в `vector_service.py` (если размерность отличается)
2. Пересоздать коллекцию в Qdrant или удалить старые векторы

### Конфигурация Qdrant

```env
# Настройки Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=  # Опционально, для облачного Qdrant
```

**Запуск Qdrant локально:**
```bash
docker run -d -p 6333:6333 qdrant/qdrant
```

### Пример работы

```python
# 1. Пользователь задает вопрос
current_query = "Как мне решить конфликт с коллегой?"

# 2. Система векторизует запрос
query_vector = embedding_model.encode(current_query)
# Результат: [0.123, -0.456, 0.789, ...] (384 числа)

# 3. Поиск в Qdrant
similar_vectors = qdrant.search(
    query_vector=query_vector,
    limit=10,
    score_threshold=0.6
)

# 4. Результаты с оценками релевантности
# [
#   {"entry_id": 123, "score": 0.85, "text": "Конфликт на работе..."},
#   {"entry_id": 456, "score": 0.72, "text": "Проблемы с начальником..."},
#   ...
# ]
```

### Преимущества векторного поиска

1. **Семантическое понимание**: Находит события по смыслу, а не по ключевым словам
2. **Мультиязычность**: Работает с русским и английским текстом
3. **Быстрота**: Поиск в миллионах векторов за миллисекунды
4. **Гибкость**: Можно комбинировать с фильтрами по метаданным

### Ограничения

1. **Требует Qdrant**: Если Qdrant недоступен, семантический поиск отключается
2. **Размерность модели**: Модель по умолчанию (384) быстрее, но менее точная, чем модели с 768 размерностью
3. **Пороги релевантности**: Нужно настраивать под конкретную задачу

## Структура модулей

### МОДУЛЬ 1: Приоритет свежести (`module_freshness.py`)

Отбор наиболее актуальных событий с учетом временнóго фактора.

**Алгоритм:**
1. Фильтрация по дате: отбор событий за указанный период
2. Временное взвешивание: расчет веса каждого события по формуле убывающей значимости
3. Ранжирование: сортировка событий по комбинированному весу (время + релевантность)
4. Лимитирование: выбор топ-N событий для включения в контекст

**Конфигурация:**
- `FRESHNESS_DEFAULT_PERIOD_DAYS`: Период охвата в днях (по умолчанию 30)
- `FRESHNESS_DEFAULT_LIMIT`: Лимит событий (по умолчанию 7)
- `FRESHNESS_DECAY_FACTOR`: Коэффициент убывания значимости (по умолчанию 0.1)
- `FRESHNESS_TIME_WEIGHT`: Вес временного фактора (по умолчанию 0.5)
- `FRESHNESS_PRIORITY_WEIGHT`: Вес приоритета (по умолчанию 0.3)
- `FRESHNESS_SIMILARITY_WEIGHT`: Вес семантической релевантности (по умолчанию 0.2)
- `FRESHNESS_MAX_PROCESSING_LIMIT`: Максимальное количество записей для обработки (по умолчанию 1000)

**Оптимизации:**
- Пагинация: ограничение количества обрабатываемых записей для предотвращения загрузки миллионов записей
- Настраиваемые веса: веса для комбинирования оценок вынесены в конфигурацию
- Общая утилита: определение категории вынесено в `utils.determine_event_category()` для избежания дублирования

### МОДУЛЬ 2: Эмоциональные маркеры (`module_emotions.py`)

Выявление и учет эмоционального контекста текущего запроса и исторических событий.

**Алгоритм:**
1. Детекция эмоций: анализ текущего запроса на наличие эмоциональных маркеров
2. Векторизация эмоций: преобразование выявленных эмоций в эмбеддинги
3. Семантический поиск: поиск исторических событий с похожей эмоциональной окраской
4. Формирование эмоционального контекста: отбор 3-5 наиболее релевантных эмоционально схожих событий

**Конфигурация:**
- `EMOTIONS_DETECTION_ENABLED`: Включить детекцию эмоций (по умолчанию true)
- `EMOTIONS_SIMILARITY_THRESHOLD`: Порог релевантности (по умолчанию 0.6)
- `EMOTIONS_MAX_RESULTS`: Максимальное количество результатов (по умолчанию 5)

### МОДУЛЬ 3: Паттерны повторения (`module_patterns.py`)

Автоматическое выявление циклических и повторяющихся ситуаций в истории пользователя.

**Алгоритм:**
1. Улучшенная кластеризация: семантическая группировка событий с использованием категорий и векторного поиска
2. Анализ частотности: подсчет повторяемости событий каждого типа
3. Временной анализ: выявление сезонности, цикличности и паттернов по дням недели
4. Выявление паттернов: идентификация циклических и повторяющихся ситуаций
5. Ранжирование паттернов: определение наиболее значимых с учетом важности и эмоций

**Конфигурация:**
- `PATTERNS_ENABLED`: Включить выявление паттернов (по умолчанию true)
- `PATTERNS_MIN_FREQUENCY`: Минимальная частота повторения (по умолчанию 3)
- `PATTERNS_MAX_RESULTS`: Максимальное количество паттернов (по умолчанию 5)
- `PATTERNS_CLUSTERING_THRESHOLD`: Порог кластеризации (по умолчанию 0.7)
- `PATTERNS_FREQUENCY_WEIGHT`: Вес частоты (по умолчанию 0.4)
- `PATTERNS_TIME_DISTRIBUTION_WEIGHT`: Вес распределения по времени (по умолчанию 0.2)
- `PATTERNS_PRIORITY_WEIGHT`: Вес приоритета событий (по умолчанию 0.2)
- `PATTERNS_EMOTIONAL_WEIGHT`: Вес эмоциональной окраски (по умолчанию 0.2)
- `PATTERNS_TEMPORAL_ENABLED`: Включить анализ временных паттернов (по умолчанию true)
- `PATTERNS_MIN_CYCLIC_INTERVAL`: Минимальный интервал для цикличности в днях (по умолчанию 7)
- `PATTERNS_SEASONALITY_ENABLED`: Включить анализ сезонности (по умолчанию true)

**Улучшения:**
- Улучшенная кластеризация: использование категорий и семантического анализа
- Временной анализ: выявление сезонности, цикличности и паттернов по дням недели
- Улучшенный расчет значимости: учет приоритета событий и эмоциональной окраски
- Настраиваемые веса: все веса для расчета значимости настраиваются через конфигурацию

### МОДУЛЬ 4: Кармические узлы (`module_karma.py`)

Идентификация и отслеживание сквозных кармических тем пользователя.

**Алгоритм:**
1. Инициализация тем: загрузка базовых кармических тем из профиля (с кэшированием)
2. Семантический мониторинг: постоянный поиск событий, релевантных кармическим темам
3. Подтверждение значимости: учет ручных маркеров и повторяемости тем
4. Актуализация списка: регулярное обновление списка активных кармических тем

**Конфигурация:**
- `KARMA_ENABLED`: Включить выявление кармических тем (по умолчанию true)
- `KARMA_SIMILARITY_THRESHOLD`: Порог релевантности (по умолчанию 0.65)
- `KARMA_MAX_THEMES`: Максимальное количество тем (по умолчанию 5)
- `KARMA_FREQUENCY_WEIGHT`: Вес частоты событий (по умолчанию 0.3)
- `KARMA_PRIORITY_WEIGHT`: Вес приоритета событий (по умолчанию 0.25)
- `KARMA_REPETITION_WEIGHT`: Вес повторяемости (по умолчанию 0.2)
- `KARMA_ASPECT_WEIGHT`: Вес астрологических аспектов (по умолчанию 0.25)
- `KARMA_CACHE_ENABLED`: Включить кэширование натальных данных (по умолчанию true)
- `KARMA_CACHE_TTL`: Время жизни кэша в секундах (по умолчанию 3600)

**Улучшения:**
- Кэширование натальных данных: использование `natal_chart_cache` для избежания повторных запросов
- Улучшенный расчет уровня проявления: учет астрологических аспектов, ретроградности планет
- Настраиваемые веса: все веса для расчета значимости настраиваются через конфигурацию
- Обработка ошибок: надежная работа при отсутствии или ошибках в астрологических данных

### МОДУЛЬ 5: Контекстные связи и синастрии (`module_contacts.py`) ⭐

**СТАТУС: Заглушка для 2 этапа реализации**

Автоматическое выявление и подключение релевантных данных о значимых людях при их упоминании в запросах пользователя.

**Планируемые подмодули:**
- 5.1: Детекция упоминаний
- 5.2: Подтверждение и согласование
- 5.3: Загрузка синастрических данных
- 5.4: Исторический контекст по контакту

### ИНТЕГРАЦИОННЫЙ МОДУЛЬ: Формирование контекстного промта (`integrator.py`)

Объединение выходных данных всех модулей в единый оптимизированный промт.

**Алгоритм:**
1. Сбор данных: получение выходных данных от всех модулей
2. Приоритизация: определение наиболее важных элементов контекста
3. Структурирование: компоновка данных по установленному шаблону
4. Оптимизация объема: контроль итогового размера контекста (исключение избыточности)

**Структура промта:**
```
USER_PROFILE: [ключевые неизменные данные]
CURRENT_SITUATION: [анализ текущего запроса]
RELEVANT_HISTORY: [3-7 самых релевантных событий]
PATTERN_INSIGHTS: [выявленные циклы и паттерны]
EMOTIONAL_CONTEXT: [эмоциональная динамика]
KARMIC_CONTEXT: [кармические темы]
```

**Конфигурация:**
- `INTEGRATOR_MAX_TOKENS`: Максимальное количество токенов (по умолчанию 1500)
- `INTEGRATOR_MAX_TIME_SECONDS`: Максимальное время обработки (по умолчанию 5)
- `INTEGRATOR_ENABLE_CACHING`: Включить кэширование (по умолчанию true)

## Рекомендации по оптимизации БД

Для улучшения производительности системы рекомендуется:

1. **Улучшенная таблица событий**: Добавить векторные представления и оптимизированные индексы
2. **Таблица кэшей**: Централизованное хранение кэшированных результатов модулей
3. **Специализированные таблицы**: Отдельные таблицы для модулей (freshness, patterns, karma)
4. **Унифицированный сервисный слой**: Единый интерфейс для работы с данными

Подробные рекомендации см. в файле `DATABASE_RECOMMENDATIONS.md`.

## Использование

### Базовое использование

```python
from app.services.context_selection import ContextIntegrator, ContextSelectionRequest
from app.services.context_selection.config import ContextSelectionConfig

# Создаем интегратор
config = ContextSelectionConfig()
integrator = ContextIntegrator(config)

# Формируем запрос
request = ContextSelectionRequest(
    user_id=1,
    current_query="Как мне решить эту проблему?",
    period_days=30,
    limit=7,
    include_emotions=True,
    include_patterns=True,
    include_karma=True,
    user_profile={
        'name': 'Пользователь',
        'sun_sign': 'Лев',
        'moon_sign': 'Скорпион',
        'ascendant_sign': 'Близнецы'
    }
)

# Получаем контекстный промт
result = integrator.build_context_prompt(request, db)

# Используем отформатированный промт
print(result.formatted_prompt)
```

### Интеграция с context_service

Система интеллектуального отбора контекста автоматически используется в `context_service`:

```python
from app.services.context_service import context_service

# Получение релевантного контекста (автоматически использует интеллектуальный отбор)
context_entries = context_service.get_relevant_context(
    db=db,
    session_id=session_id,
    user_id=user_id,
    current_message="Как мне решить эту проблему?",
    limit=10,
    use_intelligent_selection=True  # По умолчанию True
)
```

## Конфигурация

Настройки системы можно изменить через переменные окружения:

```env
# МОДУЛЬ 1: Приоритет свежести
CONTEXT_FRESHNESS_PERIOD_DAYS=30
CONTEXT_FRESHNESS_LIMIT=7
CONTEXT_FRESHNESS_DECAY_FACTOR=0.1
CONTEXT_FRESHNESS_TIME_WEIGHT=0.5
CONTEXT_FRESHNESS_PRIORITY_WEIGHT=0.3
CONTEXT_FRESHNESS_SIMILARITY_WEIGHT=0.2
CONTEXT_FRESHNESS_MAX_PROCESSING_LIMIT=1000

# МОДУЛЬ 2: Эмоциональные маркеры
CONTEXT_EMOTIONS_ENABLED=true
CONTEXT_EMOTIONS_SIMILARITY_THRESHOLD=0.6
CONTEXT_EMOTIONS_MAX_RESULTS=5

# МОДУЛЬ 3: Паттерны повторения
CONTEXT_PATTERNS_ENABLED=true
CONTEXT_PATTERNS_MIN_FREQUENCY=3
CONTEXT_PATTERNS_MAX_RESULTS=5
CONTEXT_PATTERNS_CLUSTERING_THRESHOLD=0.7
CONTEXT_PATTERNS_FREQUENCY_WEIGHT=0.4
CONTEXT_PATTERNS_TIME_DISTRIBUTION_WEIGHT=0.2
CONTEXT_PATTERNS_PRIORITY_WEIGHT=0.2
CONTEXT_PATTERNS_EMOTIONAL_WEIGHT=0.2
CONTEXT_PATTERNS_TEMPORAL_ENABLED=true
CONTEXT_PATTERNS_MIN_CYCLIC_INTERVAL=7
CONTEXT_PATTERNS_SEASONALITY_ENABLED=true

# МОДУЛЬ 4: Кармические узлы
CONTEXT_KARMA_ENABLED=true
CONTEXT_KARMA_SIMILARITY_THRESHOLD=0.65
CONTEXT_KARMA_MAX_THEMES=5
CONTEXT_KARMA_FREQUENCY_WEIGHT=0.3
CONTEXT_KARMA_PRIORITY_WEIGHT=0.25
CONTEXT_KARMA_REPETITION_WEIGHT=0.2
CONTEXT_KARMA_ASPECT_WEIGHT=0.25
CONTEXT_KARMA_CACHE_ENABLED=true
CONTEXT_KARMA_CACHE_TTL=3600

# ИНТЕГРАЦИОННЫЙ МОДУЛЬ
CONTEXT_INTEGRATOR_MAX_TOKENS=1500
CONTEXT_INTEGRATOR_MAX_TIME_SECONDS=5
CONTEXT_INTEGRATOR_CACHE=true

# Общие настройки
CONTEXT_MAX_HISTORY_YEARS=3
CONTEXT_VECTOR_SEARCH_ENABLED=true
CONTEXT_VECTOR_SEARCH_THRESHOLD=0.6
```

## Критерии успешной реализации

- **Объем контекста**: не более 1500 токенов
- **Время формирования**: не более 5 секунд
- **Релевантность ответов LLM**: улучшение на 40%+ по сравнению с простым хронологическим подходом
- **Покрытие ключевых тем**: 95%+ значимых исторических аспектов учтено в промте

## Тестирование

### Функциональное тестирование

- Проверка работы каждого модуля на изолированных данных
- Интеграционное тестирование полного цикла обработки запроса
- Регрессионное тестирование при изменении алгоритмов

### Качественное тестирование

- Сравнение качества ответов LLM с разными стратегиями отбора контекста
- Оценка пользовательской удовлетворенности релевантностью ответов
- Анализ сокращения избыточной информации в промтах

### Производительность

- Нагрузочное тестирование при различных объемах исторических данных
- Измерение времени отклика системы
- Оптимизация использования вычислительных ресурсов

## Расширение системы

### Добавление нового модуля

1. Создайте новый файл модуля в `app/services/context_selection/`
2. Реализуйте интерфейс модуля с методами обработки
3. Добавьте конфигурацию в `config.py`
4. Интегрируйте модуль в `integrator.py`

### Модификация существующих модулей

Все модули структурированы для удобного внесения правок:
- Логика обработки отделена от конфигурации
- Утилиты вынесены в отдельные функции
- Модели данных четко определены

## Документация

- `models.py`: Модели данных для системы
- `utils.py`: Вспомогательные утилиты
- `config.py`: Конфигурация модулей
- `__init__.py`: Экспорт основных классов

